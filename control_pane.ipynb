{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside __/pytorch/images__, you should find a __/style_images__ folder and a __/sample_content_images__ folder.\n",
    "\n",
    "- Inside the __/style_images__ folder is an image of Vangogh painting (titled, __sample_vangogh.jpg__) that we will be using as our sample style image. \n",
    "- Inside the __/sample_content_images__ folder, which we will use solely for the purposes of testing locally, there are 4 sample images that we will use to apply the style onto. (images are titled, __sample_%1.jpg__)\n",
    "\n",
    "The interactive notebook (__style_transfer_interactive.ipynb__) and the script (__style_transfer_script.py__) will using the above directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Tuning the style transfer hyperparameters interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is to test the style transfer scripts locally and make sure the hyper parameters are set appropriately. This will be done using the __style_transfer_interactive.ipynb__ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the notebook __/pytorch/style_transfer_interactive.ipynb__ and tune the variables following variables as desired: \n",
    "\n",
    "- STYLE_WEIGHT = 10**8\n",
    "- CONTENT_WEIGHT = 10**0\n",
    "- NUM_STEPS = 300\n",
    "\n",
    "*the defaults shown above _tend_ to work nicely for most images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the style transfer script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure that our style transfer script is running correctly on our local machine. First we need to create the directory to store the output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you changed the hyperparameters in the above section and would like to apply it, you can use the following variables: `--style-weight`, `--content-weight`, and/or `--num-steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    python style_transfer_script.py \\\n",
    "    --style-image ./images/style_images/sample_vangogh.jpg \\\n",
    "    --content-image-dir ./images/sample_content_images \\\n",
    "    --content-image-list sample_0.jpg,sample_1.jpg \\\n",
    "    --output-image-dir ./images/sample_output_images \\\n",
    "    --style-weight 100000000 \\\n",
    "    --content-weight 1 \\\n",
    "    --num-steps 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the output directory to make sure that the output images are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one of those images look like:\n",
    "\n",
    "![sample_0](pytorch/images/sample_output_images/sample_0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your video for batch style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Video: \n",
    "The first thing we need to do is to download a video that we would like to apply style transfer onto. To do so, we'll be using __youtube-dl__, a simple open source command line utility to download a video from YouTube. We'll keep the downloaded video in a new folder: __pytorch/video__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll download __youtube-dl__ and use it to download a video. In this notebook, we're going to download a short 8 minute video of someone teaching us how to raise chickens. In the download command, we'll also use the flag `-f 22` to tell __youtube_dl__ that we want to download an mp4 format with dimensions 720x1280. \n",
    "\n",
    "*Feel free to manually place your own video (mp4) file into that directory instead of using __youtube-dl__ to download one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "sudo -H pip install --upgrade youtube-dl &&\n",
    "    cd pytorch/video &&\n",
    "    youtube-dl -f 22 -o \"chicken.%(ext)s\" \"https://www.youtube.com/watch?v=D23sMvVnrow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process video with ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to use __ffmpeg__ to extract the audio file, and break up the frames of the video into separate individual images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i chicken.mp4 -vn -acodec copy chicken.aac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/images/ &&\n",
    "    mkdir chicken_frames && cd chicken_frames &&\n",
    "    ffmpeg -i ../../video/chicken.mp4 %05d_chicken.jpg -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our file system should have the following under the folder __pytorch_style_transfer__:\n",
    "```md\n",
    "├── images/\n",
    "│   ├── chicken_content_images/ [<--new]\n",
    "│   ├── sample_content_images/\n",
    "│   ├── sample_output_images/\n",
    "│   └── style_images/\n",
    "├── video/\n",
    "│   ├── chicken.mp4 [<--new]\n",
    "│   └── chicken.avi [<--new]\n",
    "├── style_transfer_interactive.ipynb\n",
    "└── style_transfer_script.ipynb\n",
    "```\n",
    "\n",
    "Now that we have all the frames of the video stored seperately as images, we are ready to scale out and try scoring in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Style Transfer Script on Azure BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use Azure BatchAI to scale out of computation to multiple GPUs in Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create your cluster using the __azure/scripts/create_cluster.py__ script.\n",
    "\n",
    "After running this command, go into the Azure portal and check that your cluster is successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: resizing; Allocated: 5; Idle: 0; Unusable: 0; Running: 5; Preparing: 0; Leaving: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: No recommended backend was available. Install the keyrings.alt package if you want to use the non-recommended backends. See README.rst for details.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python azure/scripts/create_cluster.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files into Azure Blob Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the script and model files to the fileshare using the __azure/scripts/upload_files.py__ script. \n",
    "\n",
    "After running this command, go into the Azure portal or the Azure Storage Explorer and make sure that the files are correctly uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python azure/scripts/upload_files.py \\\n",
    "    --style-transfer-script pytorch/style_transfer_script.py \\\n",
    "    --style-image pytorch/images/style_images/sample_vangogh.jpg \\\n",
    "    --content-images-dir pytorch/images/chicken_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets test that our style transfer script works on the Batch AI cluster. Use the __azure/scripts/create_job.py__ script to kick off a job. \n",
    "\n",
    "NOTE - this command could take a while to execute. Remember that this will apply style transfer onto each frame of the video - this means that the code will optimize the style transfer loss function for every frame. \n",
    "\n",
    "After running this command, go into the Azure portal under your BatchAI account to make sure the job is sucessfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Job: job0_08_02_2018_193053\n",
      "Created Job: job1_08_02_2018_193111\n",
      "Created Job: job2_08_02_2018_193128\n",
      "Created Job: job3_08_02_2018_193145\n",
      "Created Job: job4_08_02_2018_193202\n",
      "Created Job: job5_08_02_2018_193218\n",
      "Created Job: job6_08_02_2018_193235\n",
      "Created Job: job7_08_02_2018_193252\n",
      "Created Job: job8_08_02_2018_193309\n",
      "Created Job: job9_08_02_2018_193326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: No recommended backend was available. Install the keyrings.alt package if you want to use the non-recommended backends. See README.rst for details.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python azure/scripts/create_job.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the jobs finish running, you can use the Azure portal or Storage explorer to inspect the output images.\n",
    "\n",
    "Inside your Blob Container, you should notice that a new directory with the datetime-stamp is created. Output images are stored there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running it with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've tested that the BatchAI jobs are successfully created, we now want to build a docker container and check that we can run the BatchAI job from a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build the docker image using the Dockerfile which will upload all Azure utility python files as well as the __create_job.py__ file into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker build -t bai_job ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to test that the BatchAI job can be executed from the docker image we just built. Because the __create_job.py__ file requires many environment variables, we will use the __docker_run.sh__ script to pass in all the required environment variables for the image to successfully run locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    source docker_run.sh -t bai_job "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to publish the image to Dockerhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker tag bai_job <your-dockerhub-username>:bai_job &&\n",
    "    sudo docker push <your-dockerhub-username>:bai_job "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up ACI with Logic Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
