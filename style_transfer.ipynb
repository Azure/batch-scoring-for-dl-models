{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Azure to do Style Transfer on a Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will take you through how to take a video, and apply style transfer onto every frame of the video, using Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Tuning the style transfer hyperparameters interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is to test the style transfer scripts locally and make sure the hyper parameters are set appropriately. This will be done using the __style_transfer_interactive.ipynb__ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the notebook __/pytorch/style_transfer_interactive.ipynb__ and tune the variables following variables as desired: \n",
    "\n",
    "- STYLE_WEIGHT = 10**8\n",
    "- CONTENT_WEIGHT = 10**0\n",
    "- NUM_STEPS = 100\n",
    "- IMAGE_SIZE = (between 300-600px if GPU enabled)\n",
    "\n",
    "*the defaults shown above _tend_ to work nicely for most images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer: Testing the style transfer script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first section, we'll test our __style_transfer_script.py__ locally and inspect the results to see that our output images look as expected. (If they're not, we should tun the parameters in the script so that the output images look the way we want them to).\n",
    "\n",
    "The __style_transfer_script.py__ is essentially the __.py__ version of the __style_transfer_interactive.ipynb__ from above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by taking a look at the style image whose style we'd like to apply onto other images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "im1 = Image(filename=\"pytorch/images/style_images/sample_renior.jpg\", width=360)\n",
    "display(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also take a look at a sample content image that we'll apply the style transfer onto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "im1 = Image(filename=\"pytorch/images/sample_content_images/sample_0.jpg\", width=360, height=360)\n",
    "display(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to create the directory to store the output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you changed the hyperparameters in the above section and would like to apply it, you can use the following variables: `--style-weight`, `--content-weight`, `--image-size`, and/or `--num-steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    python style_transfer_script.py \\\n",
    "    --style-image ./images/style_images/sample_renior.jpg \\\n",
    "    --content-image-dir ./images/sample_content_images \\\n",
    "    --content-image-list 'sample_0.jpg' \\\n",
    "    --output-image-dir ./images/sample_output_images \\\n",
    "    --style-weight $STYLE_WEIGHT \\\n",
    "    --content-weight $CONTENT_WEIGHT \\\n",
    "    --num-steps $NUM_STEPS \\\n",
    "    --image-size $IMAGE_SIZE \\\n",
    "    --log-file 'sample_style_transfer_script'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the output directory to make sure that the output images are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one of those images look like in comparison to the original content image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "im1 = Image(filename=\"pytorch/images/sample_output_images/sample_0.jpg\")\n",
    "im2 = Image(filename=\"pytorch/images/sample_content_images/sample_0.jpg\", width=360, height=360)\n",
    "display(im1, im2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! At this point, we know that the __style_transfer_script.py__ file that we'll be running in Azure works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your video for batch style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to set up the video so that we can apply transfer onto all of the frames in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Video: \n",
    "\n",
    "The first thing we need to do is to download a video that we would like to apply style transfer onto. To do so, we'll download a short climbing video that I preloaded into a public Blob Storage, located at:\n",
    "- https://happypathspublic.blob.core.windows.net/videos/\n",
    "\n",
    "*Feel free to manually place your own video (mp4) file into that directory instead of downloading my _lovely_ orangutan video..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%set_env VIDEO_NAME=orangutan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/video && \n",
    "    wget https://happypathspublic.blob.core.windows.net/videos/${VIDEO_NAME}.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check out the video so we know what it looks like before hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "HTML('\\\n",
    "    <video width=\"360\" height=\"360\" controls> \\\n",
    "         <source src=\"pytorch/video/{0}.mp4\" type=\"video/mp4\"> \\\n",
    "    </video>'\\\n",
    "    .format(os.getenv('VIDEO_NAME'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process video with ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to use __ffmpeg__ to extract the audio file, which we will save as __chicken.aac__ under the video directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i ${VIDEO_NAME}.mp4 ${VIDEO_NAME}.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need break up the frames of the video into separate individual images. The images will be saved inside a new folder under the images directory, called __chicken_frames__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/images/ &&\n",
    "    mkdir ${VIDEO_NAME} && cd ${VIDEO_NAME} &&\n",
    "    ffmpeg -i ../../video/${VIDEO_NAME}.mp4 %05d_${VIDEO_NAME}.jpg -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of frames that the video produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/images/${VIDEO_NAME} && ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our file system should have the following under the folder __pytorch_style_transfer__:\n",
    "```md\n",
    "├── images/\n",
    "│   ├── video_name/ [<--new dir with video frames as images]\n",
    "│   ├── sample_content_images/\n",
    "│   ├── sample_output_images/\n",
    "│   └── style_images/\n",
    "├── video/\n",
    "│   ├── video_name.mp4 [<--new video]\n",
    "│   └── video_name.mp3 [<--new extracted audio file for video]\n",
    "├── style_transfer_interactive.ipynb\n",
    "└── style_transfer_script.py\n",
    "```\n",
    "\n",
    "Now that we have all the frames of the video stored seperately as images, we are ready to scale out and try scoring in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Style Transfer Script on Azure BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use Azure BatchAI to scale out of computation to multiple GPUs in Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create your cluster using the __azure/scripts/create_cluster.py__ script.\n",
    "\n",
    "This script will create the BatchAI workspace for all BatchAI resources to be created in.\n",
    "\n",
    "After running this command, go into the Azure portal and check that your cluster is successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "python azure/scripts/create_cluster.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files into Azure Blob Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the script and model files to the fileshare using __az_copy__. We'll also upload our content images to test our Batch AI jobs. \n",
    "\n",
    "After running this command, go into the Azure portal or the Azure Storage Explorer and make sure that the files are correctly uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source pytorch/style_transfer_script.py \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_SCRIPT_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/style_images/sample_renior.jpg \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_STYLE_IMG_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/${VIDEO_NAME} \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_CONTENT_DIR} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY \\\n",
    "    --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets test that our style transfer script works on the Batch AI cluster. Use the __azure/scripts/create_job.py__ script to kick off a job. \n",
    "\n",
    "Kicking off this job will also automatically create 2 additional folders in your Blob container. The first folder will be named __output_of_content_YYYY_MM_DD_HHMMSS__ and the second will be named __logs_of_content_YYYY_MM_DD_HHMMSS__. The style transfer script will automatically save all output of the style transfer to the first folder. And likewise, all logs collected from the style transfer script will be saved to the second folder.\n",
    "\n",
    "NOTE - this command could take a while to execute. Remember that this will apply style transfer onto each frame of the video - this means that the code will optimize the style transfer loss function for every frame. \n",
    "\n",
    "After running this command, go into the Azure portal under your BatchAI account to make sure the job is sucessfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python azure/scripts/create_job.py --job-batch-size 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the jobs finish running, you can use the Azure portal or Storage explorer to inspect the output images.\n",
    "\n",
    "Inside your Blob Container, you should notice that a new directory with the datetime-stamp is created. Output images are stored there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running it with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've tested that the BatchAI jobs are successfully created, we now want to build a docker container and check that we can run the BatchAI job from a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build the docker image using the Dockerfile which will upload all Azure utility python files as well as the __create_job.py__ file into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker build -t $DOCKER_IMAGE ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional] \n",
    "\n",
    "Then we test that the BatchAI job can be executed from the docker image we just built. Because the __create_job.py__ file requires many environment variables, we will use the __docker_run.sh__ script to pass in all the required environment variables for the image to successfully run locally. This step is optional as it will take several minutes to run the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    source docker_run.sh -t $DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to publish the image to Dockerhub. _Make sure you replace <your-dockerhub-username>_ with your Dockerhub username. Don't forget that you'll have to make sure you're already logged in before being able to push your image up. (`docker login`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker tag bai_job $DOCKER_USER/$DOCKER_IMAGE &&\n",
    "    sudo docker push $DOCKER_USER/$DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up ACI with Logic Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to generate the ARM deployment template for deploying ACI and Logic App to set up the trigger. We will use the __generate_trigger_arm.py__ script to generate an ARM Template (JSON) which we can use to deploy the ACI and Logic App. The script uses __azure/deployments/template.trigger_arm.json__ to generate __azure/deployments/trigger_arm.json__, which we can use to execute the deployment.\n",
    "\n",
    "If you inspect the ARM Template, you'll see that Logic App will be triggered when a new file is added to the blob. The trigger will only occur if the blob filename begins with 'trigger' and ends with '.txt'. It will then use the contents of the blob to look for the corresponding directory in that Blob Container, which it then uses as the content image file directory for the transfer.\n",
    "\n",
    "For example, if we upload a file, titled `trigger_0.txt`, with the content \"content_image_dir\", the Logic App will look for a directory in the Blob Container titled \"content_image_dir\", and start to process the images it finds in the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets generate the trigger template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure/arm &&\n",
    "    python ../scripts/generate_trigger_arm.py trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the __az cli__ to deploy the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group deployment create \\\n",
    "    --name aci_logicapp_deployment \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --template-file azure/arm/trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to trigger the process by loading something into blob. Normally, this can be done with any process (such as drag-and-drop using Storage Explorer), but for the purposes of this demo, lets do so simply with __az_copy__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a file, __foo.txt__ with the contents being the name of the directory in the blob that we want to apply style transfer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch trigger_0.txt &&\n",
    "    echo $FS_CONTENT_DIR > trigger_0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to copy that file over to storage to trigger the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source trigger_0.txt \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/trigger_0.txt \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the logs from ACI to see that everything is going smoothly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az container logs --resource-group $RESOURCE_GROUP --name $ACI_CONTAINER_GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can inspect the Azure portal to see all the moving parts:\n",
    "- Logic Apps will be triggers and will spin up ACI\n",
    "- ACI will break up the content images in blob and create BatchAI jobs\n",
    "- The BatchAI cluster will scale up and start processing the work\n",
    "- As the style transfer script is executed in batch on BatchAI, we will see the completed images (as well as logs) saved back to blob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results and Re-stitch Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to download and restitch the video so that we can enjoy the same video, but now with each frame with style transfer applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get the name of the output folder where all out style transfered frames are stored. We do this by using the Batch AI CLI. We store the name of the output folder as `output_folder_name` to be used in later cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We use `--query [-1].name` to mean: 'get the name of the last experiment'\n",
    "exp_names = !az batchai experiment list -g ${RESOURCE_GROUP} --workspace ${WORKSPACE} --query [-1].name\n",
    "\n",
    "# strip quotation marks\n",
    "exp_name = str(exp_names[0])[1:-1]\n",
    "\n",
    "# replace experiment prefix with output folder prefix\n",
    "exp_name_array = str(exp_name).split('_')\n",
    "exp_name_array[0] = \"{0}_{1}\".format(os.getenv('FS_OUTPUT_DIR_PREFIX'), os.getenv('FS_CONTENT_DIR'))\n",
    "output_folder_name = '_'.join(exp_name_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `output_folder_name` variable, lets download the frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env output_folder_name=\"$output_folder_name\" bash\n",
    "cd pytorch/images &&\n",
    "    azcopy \\\n",
    "        --source https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME} \\\n",
    "        --destination . \\\n",
    "        --source-key $STORAGE_ACCOUNT_KEY \\\n",
    "        --include $output_folder_name \\\n",
    "        --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets use ffmpeg to stitch independent frames back into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env output_folder_name=\"$output_folder_name\" bash\n",
    "cd pytorch &&\n",
    "    ffmpeg \\\n",
    "        -framerate 30 \\\n",
    "        -i images/$output_folder_name/%05d_${VIDEO_NAME}.jpg \\\n",
    "        -c:v libx264 \\\n",
    "        -profile:v high -crf 20 -pix_fmt yuv420p \\\n",
    "        -y \\\n",
    "        video/${VIDEO_NAME}_processed_without_audio.mp4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i ${VIDEO_NAMEVIDEO_NAME}_processed_without_audio.mp4 -i ${VIDEO_NAME}.mp3 \\\n",
    "        -map 0:0 -map 1:0 \\\n",
    "        -vcodec copy -acodec copy \\\n",
    "        -y \\\n",
    "        ${VIDEO_NAME}_processed_with_audio.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "HTML('\\\n",
    "    <video width=\"360\" height=\"360\" controls> \\\n",
    "         <source src=\"pytorch/video/{0}_processed_with_audio.mp4\" type=\"video/mp4\"> \\\n",
    "    </video>'\\\n",
    "    .format(os.getenv('VIDEO_NAME'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import os\n",
    "im1 = Image(filename=\"pytorch/images/{0}/00001_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "im2 = Image(filename=\"pytorch/images/{0}/00100_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "im3 = Image(filename=\"pytorch/images/{0}/00300_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "im4 = Image(filename=\"pytorch/images/{0}/00500_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "display(im1, im2, im3, im4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its always good to clean up your Azure resources after you've completed your workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group delete --name $RESOURCE_GROUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
