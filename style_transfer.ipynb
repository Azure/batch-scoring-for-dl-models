{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside __/pytorch/images__, you should find a __/style_images__ folder and a __/sample_content_images__ folder.\n",
    "\n",
    "- Inside the __/style_images__ folder is an image of Vangogh painting (titled, __sample_vangogh.jpg__) that we will be using as our sample style image. \n",
    "- Inside the __/sample_content_images__ folder, which we will use solely for the purposes of testing locally, there are 4 sample images that we will use to apply the style onto. (images are titled, __sample_%1.jpg__)\n",
    "\n",
    "The interactive notebook (__style_transfer_interactive.ipynb__) and the script (__style_transfer_script.py__) will using the above directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Tuning the style transfer hyperparameters interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is to test the style transfer scripts locally and make sure the hyper parameters are set appropriately. This will be done using the __style_transfer_interactive.ipynb__ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the notebook __/pytorch/style_transfer_interactive.ipynb__ and tune the variables following variables as desired: \n",
    "\n",
    "- STYLE_WEIGHT = 10**8\n",
    "- CONTENT_WEIGHT = 10**0\n",
    "- NUM_STEPS = 300\n",
    "\n",
    "*the defaults shown above _tend_ to work nicely for most images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the style transfer script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure that our style transfer script is running correctly on our local machine. First we need to create the directory to store the output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you changed the hyperparameters in the above section and would like to apply it, you can use the following variables: `--style-weight`, `--content-weight`, and/or `--num-steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-13 18:01:42,168 - __main__ - DEBUG - Images to process: 2\n",
      "2018-08-13 18:01:42,168 - __main__ - DEBUG - GPU detected: True, image size: 512\n",
      "2018-08-13 18:01:45,877 - __main__ - DEBUG - Time (in seconds) to load style image: 3.708443\n",
      "2018-08-13 18:01:47,387 - __main__ - DEBUG - Time (in seconds) to load VGG19 model: 1.509391\n",
      "2018-08-13 18:01:47,403 - __main__ - DEBUG - Time (in seconds) to apply style-transfer to batch of 2 images: 0.016245\n",
      "2018-08-13 18:01:47,404 - __main__ - DEBUG - Average Time (in seconds) to apply style-transfer to each image: 0.008122\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    python style_transfer_script.py \\\n",
    "    --style-image ./images/style_images/sample_vangogh.jpg \\\n",
    "    --content-image-dir ./images/sample_content_images \\\n",
    "    --content-image-list sample_0.jpg,sample_1.jpg \\\n",
    "    --output-image-dir ./images/sample_output_images \\\n",
    "    --style-weight 100000000 \\\n",
    "    --content-weight 1 \\\n",
    "    --num-steps 300 \\\n",
    "    --log-file 'sample_style_transfer_script'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the output directory to make sure that the output images are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one of those images look like:\n",
    "\n",
    "![sample_0](pytorch/images/sample_output_images/sample_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your video for batch style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Video: \n",
    "_TODO - update to use MSFT compliant video_\n",
    "\n",
    "The first thing we need to do is to download a video that we would like to apply style transfer onto. To do so, we'll be using __youtube-dl__, a simple open source command line utility to download a video from YouTube. We'll keep the downloaded video in a new folder: __pytorch/video__. \n",
    "\n",
    "First we'll download __youtube-dl__ and use it to download a video. In this notebook, we're going to download a short one and a half minute video of chickens. In the download command, we'll also use the flag `-f 22` to tell __youtube_dl__ that we want to download an mp4 format with dimensions 720x1280. \n",
    "\n",
    "*Feel free to manually place your own video (mp4) file into that directory instead of using __youtube-dl__ to download one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube-dl\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/3b/17a27fecceb768ebec9e0d650fb764d47a5810b6840ea77177f128e2f0a8/youtube_dl-2018.8.4-py2.py3-none-any.whl (1.7MB)\n",
      "Installing collected packages: youtube-dl\n",
      "  Found existing installation: youtube-dl 2018.7.29\n",
      "    Uninstalling youtube-dl-2018.7.29:\n",
      "      Not removing or modifying (outside of prefix):\n",
      "      /usr/bin/youtube-dl\n",
      "      Successfully uninstalled youtube-dl-2018.7.29\n",
      "Successfully installed youtube-dl-2018.8.4\n",
      "[youtube] D23sMvVnrow: Downloading webpage\n",
      "[youtube] D23sMvVnrow: Downloading video info webpage\n",
      "[download] Destination: chicken.mp4\n",
      "\r",
      "[download]   0.0% of 23.41MiB at Unknown speed ETA Unknown ETA\r",
      "[download]   0.0% of 23.41MiB at Unknown speed ETA Unknown ETA\r",
      "[download]   0.0% of 23.41MiB at Unknown speed ETA Unknown ETA\r",
      "[download]   0.1% of 23.41MiB at  2.77MiB/s ETA 00:08\r",
      "[download]   0.1% of 23.41MiB at  3.75MiB/s ETA 00:06\r",
      "[download]   0.3% of 23.41MiB at  5.19MiB/s ETA 00:04\r",
      "[download]   0.5% of 23.41MiB at  7.26MiB/s ETA 00:03\r",
      "[download]   1.1% of 23.41MiB at 11.12MiB/s ETA 00:02\r",
      "[download]   2.1% of 23.41MiB at 17.67MiB/s ETA 00:01\r",
      "[download]   4.3% of 23.41MiB at 28.30MiB/s ETA 00:00\r",
      "[download]   8.5% of 23.41MiB at 47.63MiB/s ETA 00:00\r",
      "[download]  17.1% of 23.41MiB at 66.30MiB/s ETA 00:00\r",
      "[download]  34.2% of 23.41MiB at 80.13MiB/s ETA 00:00\r",
      "[download]  51.3% of 23.41MiB at 75.81MiB/s ETA 00:00\r",
      "[download]  68.3% of 23.41MiB at 64.73MiB/s ETA 00:00\r",
      "[download]  85.4% of 23.41MiB at 55.62MiB/s ETA 00:00\r",
      "[download] 100.0% of 23.41MiB at 59.28MiB/s ETA 00:00\r",
      "[download] 100% of 23.41MiB in 00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.1.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo -H pip install --upgrade youtube-dl &&\n",
    "    cd pytorch/video &&\n",
    "    youtube-dl -f 22 -o \"chicken.%(ext)s\" \"https://www.youtube.com/watch?v=D23sMvVnrow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process video with ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to use __ffmpeg__ to extract the audio file, which we will save as __chicken.aac__ under the video directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 2.8.14-0ubuntu0.16.04.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.9) 20160609\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv\n",
      "  libavutil      54. 31.100 / 54. 31.100\n",
      "  libavcodec     56. 60.100 / 56. 60.100\n",
      "  libavformat    56. 40.101 / 56. 40.101\n",
      "  libavdevice    56.  4.100 / 56.  4.100\n",
      "  libavfilter     5. 40.101 /  5. 40.101\n",
      "  libavresample   2.  1.  0 /  2.  1.  0\n",
      "  libswscale      3.  1.101 /  3.  1.101\n",
      "  libswresample   1.  2.101 /  1.  2.101\n",
      "  libpostproc    53.  3.100 / 53.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'chicken.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2017-09-23 09:38:19\n",
      "  Duration: 00:01:39.61, start: 0.000000, bitrate: 1971 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 1842 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "Output #0, adts, to 'chicken.aac':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf56.40.101\n",
      "    Stream #0:0(und): Audio: aac (mp4a / 0x6134706D), 44100 Hz, stereo, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "size=    1557kB time=00:01:39.61 bitrate= 128.0kbits/s    \n",
      "video:0kB audio:1527kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.920026%\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i chicken.mp4 -vn -acodec copy chicken.aac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need break up the frames of the video into separate individual images. The images will be saved inside a new folder under the images directory, called __chicken_frames__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../../video/chicken.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2017-09-23 09:38:19\n",
      "  Duration: 00:01:39.61, start: 0.000000, bitrate: 1971 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 1842 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "[swscaler @ 0x26a9d60] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to '%05d_chicken.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf56.40.101\n",
      "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "      encoder         : Lavc56.60.100 mjpeg\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "frame=   86 fps=0.0 q=24.8 size=N/A time=00:00:03.44 bitrate=N/A    \r",
      "frame=  178 fps=177 q=24.8 size=N/A time=00:00:07.12 bitrate=N/A    \r",
      "frame=  269 fps=178 q=24.8 size=N/A time=00:00:10.76 bitrate=N/A    \r",
      "frame=  363 fps=180 q=24.8 size=N/A time=00:00:14.52 bitrate=N/A    \r",
      "frame=  455 fps=181 q=24.8 size=N/A time=00:00:18.20 bitrate=N/A    \r",
      "frame=  542 fps=179 q=24.8 size=N/A time=00:00:21.68 bitrate=N/A    \r",
      "frame=  628 fps=178 q=24.8 size=N/A time=00:00:25.12 bitrate=N/A    \r",
      "frame=  719 fps=179 q=24.8 size=N/A time=00:00:28.76 bitrate=N/A    \r",
      "frame=  806 fps=178 q=24.8 size=N/A time=00:00:32.24 bitrate=N/A    \r",
      "frame=  890 fps=177 q=24.8 size=N/A time=00:00:35.60 bitrate=N/A    \r",
      "frame=  971 fps=175 q=24.8 size=N/A time=00:00:38.84 bitrate=N/A    \r",
      "frame= 1051 fps=174 q=24.8 size=N/A time=00:00:42.04 bitrate=N/A    \r",
      "frame= 1131 fps=173 q=24.8 size=N/A time=00:00:45.24 bitrate=N/A    \r",
      "frame= 1211 fps=172 q=24.8 size=N/A time=00:00:48.44 bitrate=N/A    \r",
      "frame= 1291 fps=171 q=24.8 size=N/A time=00:00:51.64 bitrate=N/A    \r",
      "frame= 1369 fps=170 q=24.8 size=N/A time=00:00:54.76 bitrate=N/A    \r",
      "frame= 1448 fps=169 q=24.8 size=N/A time=00:00:57.92 bitrate=N/A    \r",
      "frame= 1526 fps=168 q=24.8 size=N/A time=00:01:01.04 bitrate=N/A    \r",
      "frame= 1604 fps=168 q=24.8 size=N/A time=00:01:04.16 bitrate=N/A    \r",
      "frame= 1682 fps=167 q=24.8 size=N/A time=00:01:07.28 bitrate=N/A    \r",
      "frame= 1762 fps=167 q=24.8 size=N/A time=00:01:10.48 bitrate=N/A    \r",
      "frame= 1840 fps=166 q=24.8 size=N/A time=00:01:13.60 bitrate=N/A    \r",
      "frame= 1920 fps=166 q=24.8 size=N/A time=00:01:16.80 bitrate=N/A    \r",
      "frame= 2002 fps=166 q=24.8 size=N/A time=00:01:20.08 bitrate=N/A    \r",
      "frame= 2085 fps=166 q=24.8 size=N/A time=00:01:23.40 bitrate=N/A    \r",
      "frame= 2170 fps=166 q=24.8 size=N/A time=00:01:26.80 bitrate=N/A    \r",
      "frame= 2254 fps=166 q=24.8 size=N/A time=00:01:30.16 bitrate=N/A    \r",
      "frame= 2335 fps=166 q=24.8 size=N/A time=00:01:33.40 bitrate=N/A    \r",
      "frame= 2419 fps=166 q=24.8 size=N/A time=00:01:36.76 bitrate=N/A    \r",
      "frame= 2490 fps=166 q=24.8 Lsize=N/A time=00:01:39.60 bitrate=N/A    \n",
      "video:101655kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/images/ &&\n",
    "    mkdir chicken_frames && cd chicken_frames &&\n",
    "    ffmpeg -i ../../video/chicken.mp4 %05d_chicken.jpg -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of frames that the video produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2490\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/images/chicken_frames && ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our file system should have the following under the folder __pytorch_style_transfer__:\n",
    "```md\n",
    "├── images/\n",
    "│   ├── chicken_frames/ [<--new dir with video frames as images]\n",
    "│   ├── sample_content_images/\n",
    "│   ├── sample_output_images/\n",
    "│   └── style_images/\n",
    "├── video/\n",
    "│   ├── chicken.mp4 [<--new video]\n",
    "│   └── chicken.avi [<--new extracted audio file for video]\n",
    "├── style_transfer_interactive.ipynb\n",
    "└── style_transfer_script.py\n",
    "```\n",
    "\n",
    "Now that we have all the frames of the video stored seperately as images, we are ready to scale out and try scoring in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Style Transfer Script on Azure BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use Azure BatchAI to scale out of computation to multiple GPUs in Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create your cluster using the __azure/scripts/create_cluster.py__ script.\n",
    "\n",
    "After running this command, go into the Azure portal and check that your cluster is successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: steady; Allocated: 0; Idle: 0; Unusable: 0; Running: 0; Preparing: 0; Leaving: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: No recommended backend was available. Install the keyrings.alt package if you want to use the non-recommended backends. See README.rst for details.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python azure/scripts/create_cluster.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files into Azure Blob Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the script and model files to the fileshare using __az_copy__. We'll also upload our content images to test our Batch AI jobs. \n",
    "\n",
    "After running this command, go into the Azure portal or the Azure Storage Explorer and make sure that the files are correctly uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018/08/13 18:06:51][WARNING] The command line \"--source \"pytorch/images/chicken_frames\" --destination \"https://jsblobplayground.blob.core.windows.net/batchai/content\" --recursive --dest-key ******\" in the journal file \"/home/jiata/Microsoft/Azure/AzCopy/AzCopy.jnl\" is different from your input.\n",
      "[2018/08/13 18:06:51][WARNING] Incomplete operation with different command line detected at the journal directory \"/home/jiata/Microsoft/Azure/AzCopy\".\n",
      "[2018/08/13 18:06:52] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:00\n",
      "[2018/08/13 18:06:53] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:00\n",
      "[2018/08/13 18:06:55] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 2490\n",
      "Transfer successfully:   2490\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:02\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source pytorch/style_transfer_script.py \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_SCRIPT_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/style_images/sample_vangogh.jpg \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_STYLE_IMG_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/chicken_frames \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_CONTENT_DIR} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY \\\n",
    "    --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets test that our style transfer script works on the Batch AI cluster. Use the __azure/scripts/create_job.py__ script to kick off a job. \n",
    "\n",
    "NOTE - this command could take a while to execute. Remember that this will apply style transfer onto each frame of the video - this means that the code will optimize the style transfer loss function for every frame. \n",
    "\n",
    "After running this command, go into the Azure portal under your BatchAI account to make sure the job is sucessfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-13 18:08:17,334 - __main__ - DEBUG - Created job #0, named job0_08_13_2018_180759, with 100 images.\n",
      "2018-08-13 18:08:34,850 - __main__ - DEBUG - Created job #1, named job1_08_13_2018_180817, with 100 images.\n",
      "2018-08-13 18:08:51,533 - __main__ - DEBUG - Created job #2, named job2_08_13_2018_180834, with 100 images.\n",
      "2018-08-13 18:09:09,173 - __main__ - DEBUG - Created job #3, named job3_08_13_2018_180851, with 100 images.\n",
      "2018-08-13 18:09:26,249 - __main__ - DEBUG - Created job #4, named job4_08_13_2018_180909, with 100 images.\n",
      "2018-08-13 18:09:42,504 - __main__ - DEBUG - Created job #5, named job5_08_13_2018_180926, with 100 images.\n",
      "2018-08-13 18:09:58,835 - __main__ - DEBUG - Created job #6, named job6_08_13_2018_180942, with 100 images.\n",
      "2018-08-13 18:10:15,412 - __main__ - DEBUG - Created job #7, named job7_08_13_2018_180958, with 100 images.\n",
      "2018-08-13 18:10:32,120 - __main__ - DEBUG - Created job #8, named job8_08_13_2018_181015, with 100 images.\n",
      "2018-08-13 18:10:48,525 - __main__ - DEBUG - Created job #9, named job9_08_13_2018_181032, with 100 images.\n",
      "2018-08-13 18:11:05,257 - __main__ - DEBUG - Created job #10, named job10_08_13_2018_181048, with 100 images.\n",
      "2018-08-13 18:11:22,446 - __main__ - DEBUG - Created job #11, named job11_08_13_2018_181105, with 100 images.\n",
      "2018-08-13 18:11:38,895 - __main__ - DEBUG - Created job #12, named job12_08_13_2018_181122, with 100 images.\n",
      "2018-08-13 18:11:56,520 - __main__ - DEBUG - Created job #13, named job13_08_13_2018_181138, with 100 images.\n",
      "2018-08-13 18:12:13,572 - __main__ - DEBUG - Created job #14, named job14_08_13_2018_181156, with 100 images.\n",
      "2018-08-13 18:12:29,460 - __main__ - DEBUG - Created job #15, named job15_08_13_2018_181213, with 100 images.\n",
      "2018-08-13 18:12:45,703 - __main__ - DEBUG - Created job #16, named job16_08_13_2018_181229, with 100 images.\n",
      "2018-08-13 18:13:03,352 - __main__ - DEBUG - Created job #17, named job17_08_13_2018_181245, with 100 images.\n",
      "2018-08-13 18:13:20,534 - __main__ - DEBUG - Created job #18, named job18_08_13_2018_181303, with 100 images.\n",
      "2018-08-13 18:13:37,442 - __main__ - DEBUG - Created job #19, named job19_08_13_2018_181320, with 100 images.\n",
      "2018-08-13 18:13:54,084 - __main__ - DEBUG - Created job #20, named job20_08_13_2018_181337, with 100 images.\n",
      "2018-08-13 18:14:11,143 - __main__ - DEBUG - Created job #21, named job21_08_13_2018_181354, with 100 images.\n",
      "2018-08-13 18:14:27,394 - __main__ - DEBUG - Created job #22, named job22_08_13_2018_181411, with 100 images.\n",
      "2018-08-13 18:14:43,893 - __main__ - DEBUG - Created job #23, named job23_08_13_2018_181427, with 100 images.\n",
      "2018-08-13 18:15:00,783 - __main__ - DEBUG - Created job #24, named job24_08_13_2018_181443, with 90 images.\n",
      "2018-08-13 18:15:00,783 - __main__ - DEBUG - Time (in seconds) it took to create all BatchAI jobs: 420.9356379508972\n",
      "2018-08-13 18:15:00,783 - __main__ - DEBUG - Time (in seconds) it takes to create a single BatchAI job on average: 17.538984914620716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: No recommended backend was available. Install the keyrings.alt package if you want to use the non-recommended backends. See README.rst for details.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python azure/scripts/create_job.py --job-batch-size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the jobs finish running, you can use the Azure portal or Storage explorer to inspect the output images.\n",
    "\n",
    "Inside your Blob Container, you should notice that a new directory with the datetime-stamp is created. Output images are stored there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running it with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've tested that the BatchAI jobs are successfully created, we now want to build a docker container and check that we can run the BatchAI job from a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build the docker image using the Dockerfile which will upload all Azure utility python files as well as the __create_job.py__ file into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker build -t $DOCKER_IMAGE ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to test that the BatchAI job can be executed from the docker image we just built. Because the __create_job.py__ file requires many environment variables, we will use the __docker_run.sh__ script to pass in all the required environment variables for the image to successfully run locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    source docker_run.sh -t $DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to publish the image to Dockerhub. _Make sure you replace <your-dockerhub-username>_ with your Dockerhub username. Don't forget that you'll have to make sure you're already logged in before being able to push your image up. (`docker login`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker tag bai_job $DOCKER_USERNAME:$DOCKER_IMAGE &&\n",
    "    sudo docker push $DOCKER_USERNAME:$DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up ACI with Logic Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to generate the ARM deployment template for deploying ACI and Logic App to set up the trigger. We will use the __generate_trigger_arm.py__ script to generate an ARM Template (JSON) which we can use to deploy the ACI and Logic App. The script uses __azure/deployments/template.trigger_arm.json__ to generate __azure/deployments/trigger_arm.json__, which we can use to execute the deployment.\n",
    "\n",
    "If you inspect the ARM Template, you'll see that Logic App will be triggered when a new file is added to the blob. It will then use the contents of the blob and look for a directory in that Blob Container and use it as the content image file directory for the transfer.\n",
    "\n",
    "For example, if we upload a file, titled `foo.txt`, with the content \"content_image_dir\", the Logic App will look for a directory in the Blob Container titled \"content_image_dir\", and start to process the images it finds in the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets generate the trigger template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure/deployments &&\n",
    "    python ../scripts/generate_trigger_arm.py trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the __az cli__ to deploy the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group deployment create \\\n",
    "    --name aci_logicapp_deployment \\\n",
    "    --resource-group $RESOURE_GROUP \\\n",
    "    --template-file azure/deployments/trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to trigger the process by loading something into blob. Normally, this can be done with any process, but for the purposes of this demo, lets do so simply with __az_copy__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a file, __foo.txt__ with the contents being the name of the directory in the blob that we want to apply style transfer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch foo.txt &&\n",
    "    echo $FS_CONTENT_DIR > foo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to copy that file over to storage to trigger the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source foo.txt \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/foo.txt \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can inspect the Azure portal to see all the moving parts:\n",
    "- Logic Apps will be triggers and will spin up ACI\n",
    "- ACI will break up the content images in blob and create BatchAI jobs\n",
    "- The BatchAI cluster will scale up and start processing the work\n",
    "- As the style transfer script is executed in batch on BatchAI, we will see the completed images (as well as logs) saved back to blob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results and Re-stitch Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to download and restitch the video so that we can enjoy the same video, but now with each frame with style transfer applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to download the frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/images &&\n",
    "    azcopy \\\n",
    "        --source https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME} \\\n",
    "        --destination . \\\n",
    "        --source-key $STORAGE_ACCOUNT_KEY \\\n",
    "        --include \"output_content_08_08_2018_162725\" \\\n",
    "        --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets use ffmpeg to stitch independent frames back into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    ffmpeg \\\n",
    "        -framerate 30 \\\n",
    "        -i images/\"output_content_08_08_2018_162725\"/%05d_chicken.jpg \\\n",
    "        -c:v libx264 \\\n",
    "        -profile:v high -crf 20 -pix_fmt yuv420p \\\n",
    "        video/chicken_processed.mp4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
