{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Azure to do Style Transfer on a Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will take you through how to take a video, and apply style transfer onto every frame of the video, using Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, HTML\n",
    "import os\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Tuning the style transfer hyperparameters interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is to test the style transfer scripts locally and make sure the hyper parameters are set appropriately. This will be done using the __style_transfer_interactive.ipynb__ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the notebook __/pytorch/style_transfer_interactive.ipynb__ and tune the variables following variables as desired: \n",
    "\n",
    "- STYLE_WEIGHT = 10**8\n",
    "- CONTENT_WEIGHT = 10**0\n",
    "- NUM_STEPS = 100\n",
    "- IMAGE_SIZE = (between 300-600px if GPU enabled)\n",
    "\n",
    "*the defaults shown above _tend_ to work nicely for most images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style Transfer: Testing the style transfer script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first section, we'll test our __style_transfer_script.py__ locally and inspect the results to see that our output images look as expected. (If they're not, we should tun the parameters in the script so that the output images look the way we want them to).\n",
    "\n",
    "The __style_transfer_script.py__ is essentially the __.py__ version of the __style_transfer_interactive.ipynb__ from above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by taking a look at the style image whose style we'd like to apply onto other images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image(filename=\"pytorch/images/style_images/sample_renior.jpg\", width=360)\n",
    "display(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also take a look at a sample content image that we'll apply the style transfer onto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image(filename=\"pytorch/images/sample_content_images/sample_0.jpg\", width=360, height=360)\n",
    "display(im1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to create the directory to store the output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you changed the hyperparameters in the above section and would like to apply it, you can use the following variables: `--style-weight`, `--content-weight`, `--image-size`, and/or `--num-steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 19:00:46,796 - __main__ - DEBUG - Images to process: 1\n",
      "2018-09-18 19:00:46,796 - __main__ - DEBUG - GPU detected: True, image size: 512\n",
      "2018-09-18 19:00:48,039 - __main__ - DEBUG - Time (in seconds) to load style image: 1.242270\n",
      "2018-09-18 19:00:49,489 - __main__ - DEBUG - Time (in seconds) to load VGG19 model: 1.449398\n",
      "2018-09-18 19:00:49,534 - __main__ - DEBUG - Running Style Transfer on sample_0.jpg\n",
      "2018-09-18 19:00:55,924 - __main__ - DEBUG - Time (in seconds) to apply style-transfer to batch of 1 images: 6.435271\n",
      "2018-09-18 19:00:55,924 - __main__ - DEBUG - Average Time (in seconds) to apply style-transfer to each image: 6.435271\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    python style_transfer_script.py \\\n",
    "    --style-image ./images/style_images/sample_renior.jpg \\\n",
    "    --content-image-dir ./images/sample_content_images \\\n",
    "    --content-image-list 'sample_0.jpg' \\\n",
    "    --output-image-dir ./images/sample_output_images \\\n",
    "    --style-weight $STYLE_WEIGHT \\\n",
    "    --content-weight $CONTENT_WEIGHT \\\n",
    "    --num-steps $NUM_STEPS \\\n",
    "    --image-size $IMAGE_SIZE \\\n",
    "    --log-file 'sample_style_transfer_script'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the output directory to make sure that the output images are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one of those images look like in comparison to the original content image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image(filename=\"pytorch/images/sample_output_images/sample_0.jpg\")\n",
    "im2 = Image(filename=\"pytorch/images/sample_content_images/sample_0.jpg\", width=360, height=360)\n",
    "display(im1, im2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! At this point, we know that the __style_transfer_script.py__ file that we'll be running in Azure works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your video for batch style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to set up the video so that we can apply transfer onto all of the frames in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Video: \n",
    "\n",
    "The first thing we need to do is to download a video that we would like to apply style transfer onto. To do so, we'll download a short climbing video that I preloaded into a public Blob Storage, located at:\n",
    "- https://happypathspublic.blob.core.windows.net/videos/\n",
    "\n",
    "*Feel free to manually place your own video (mp4) file into that directory instead of downloading my _lovely_ orangutan video..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VIDEO_NAME=orangutan\n"
     ]
    }
   ],
   "source": [
    "%set_env VIDEO_NAME=orangutan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2018-09-18 19:08:49--  https://happypathspublic.blob.core.windows.net/videos/orangutan.mp4\n",
      "Resolving happypathspublic.blob.core.windows.net (happypathspublic.blob.core.windows.net)... 52.239.214.164\n",
      "Connecting to happypathspublic.blob.core.windows.net (happypathspublic.blob.core.windows.net)|52.239.214.164|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7961293 (7.6M) [video/mp4]\n",
      "Saving to: ‘orangutan.mp4’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  104M 0s\n",
      "    50K .......... .......... .......... .......... ..........  1%  173M 0s\n",
      "   100K .......... .......... .......... .......... ..........  1%  112M 0s\n",
      "   150K .......... .......... .......... .......... ..........  2%  187M 0s\n",
      "   200K .......... .......... .......... .......... ..........  3%  337M 0s\n",
      "   250K .......... .......... .......... .......... ..........  3% 88.8M 0s\n",
      "   300K .......... .......... .......... .......... ..........  4%  176M 0s\n",
      "   350K .......... .......... .......... .......... ..........  5%  206M 0s\n",
      "   400K .......... .......... .......... .......... ..........  5%  216M 0s\n",
      "   450K .......... .......... .......... .......... ..........  6%  160M 0s\n",
      "   500K .......... .......... .......... .......... ..........  7%  233M 0s\n",
      "   550K .......... .......... .......... .......... ..........  7%  246M 0s\n",
      "   600K .......... .......... .......... .......... ..........  8%  270M 0s\n",
      "   650K .......... .......... .......... .......... ..........  9%  268M 0s\n",
      "   700K .......... .......... .......... .......... ..........  9%  278M 0s\n",
      "   750K .......... .......... .......... .......... .......... 10% 28.0M 0s\n",
      "   800K .......... .......... .......... .......... .......... 10%  268M 0s\n",
      "   850K .......... .......... .......... .......... .......... 11%  274M 0s\n",
      "   900K .......... .......... .......... .......... .......... 12%  150M 0s\n",
      "   950K .......... .......... .......... .......... .......... 12%  229M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 13%  160M 0s\n",
      "  1050K .......... .......... .......... .......... .......... 14%  192M 0s\n",
      "  1100K .......... .......... .......... .......... .......... 14%  256M 0s\n",
      "  1150K .......... .......... .......... .......... .......... 15%  155M 0s\n",
      "  1200K .......... .......... .......... .......... .......... 16%  203M 0s\n",
      "  1250K .......... .......... .......... .......... .......... 16%  234M 0s\n",
      "  1300K .......... .......... .......... .......... .......... 17%  264M 0s\n",
      "  1350K .......... .......... .......... .......... .......... 18%  239M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 18% 41.6M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 19%  262M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 19%  261M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 20%  229M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 21%  207M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 21%  312M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 22%  367M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 23% 11.8M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 23%  259M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 24%  174M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 25%  256M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 25%  142M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 26%  170M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 27%  264M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 27%  155M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 28%  142M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 28%  263M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 29% 23.0M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 30%  172M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 30% 90.4M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 31%  264M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 32%  204M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 32%  185M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 33%  202M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 34%  259M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 34%  251M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 35%  265M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 36%  211M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 36%  259M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 37%  261M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 37%  202M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 38%  218M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 39%  178M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 39%  210M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 40%  188M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 41%  181M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 41%  267M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 42%  369M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 43%  387M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 43%  323M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 44%  270M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 45%  273M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 45%  241M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 46%  225M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 46%  272M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 47%  275M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 48%  276M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 48%  223M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 49%  191M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 50%  184M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 50%  255M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 51%  157M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 52%  175M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 52%  245M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 53%  142M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 54%  171M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 54%  251M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 55%  294M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 55%  282M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 56%  284M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 57%  215M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 57%  293M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 58%  284M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 59%  296M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 59%  259M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 60%  271M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 61%  279M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 61%  192M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 62%  169M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 63%  284M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 63%  176M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 64%  202M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 64%  136M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 65%  161M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 66%  273M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 66%  269M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 67%  246M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 68%  200M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 68%  170M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 69%  199M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 70%  254M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 70%  220M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 71%  256M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 72%  211M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 72%  224M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 73%  191M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 73%  288M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 74%  192M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 75%  194M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 75%  211M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 76%  268M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 77%  271M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 77%  154M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 78%  198M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 79%  266M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 79%  287M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 80%  163M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 81%  235M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 81%  286M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 82%  270M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 82%  223M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 83%  285M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 84%  286M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 84%  269M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 85%  250M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 86%  289M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 86%  272M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 87%  287M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 88%  240M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 88%  280M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 89%  295M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 90%  272M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 90%  249M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 91%  275M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 91%  286M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 92%  279M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 93%  242M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 93%  269M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 94%  281M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 95%  286M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 95%  263M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 96%  279M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 97%  289M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 97%  274M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 98%  242M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 99%  282M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 99%  286M 0s\n",
      "  7750K .......... .......... ....                            100%  293M=0.04s\n",
      "\n",
      "2018-09-18 19:08:49 (178 MB/s) - ‘orangutan.mp4’ saved [7961293/7961293]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/video && \n",
    "    wget https://happypathspublic.blob.core.windows.net/videos/${VIDEO_NAME}.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check out the video so we know what it looks like before hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <video width=\"360\" height=\"360\" controls>          <source src=\"pytorch/video/orangutan.mp4\" type=\"video/mp4\">     </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('\\\n",
    "    <video width=\"360\" height=\"360\" controls> \\\n",
    "         <source src=\"pytorch/video/{0}.mp4\" type=\"video/mp4\"> \\\n",
    "    </video>'\\\n",
    "    .format(os.getenv('VIDEO_NAME'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process video with ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to use __ffmpeg__ to extract the audio file, which we will save as __chicken.aac__ under the video directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.4-0ubuntu0.18.04.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'orangutan.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:27.48, start: 0.000000, bitrate: 2317 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x720, 2242 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp3, to 'orangutan.mp3':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    TSSE            : Lavf57.83.100\n",
      "    Stream #0:0(eng): Audio: mp3 (libmp3lame), 48000 Hz, mono, fltp (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      encoder         : Lavc57.107.100 libmp3lame\n",
      "size=     215kB time=00:00:27.45 bitrate=  64.2kbits/s speed=75.8x    \n",
      "video:0kB audio:215kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.154658%\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i ${VIDEO_NAME}.mp4 ${VIDEO_NAME}.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need break up the frames of the video into separate individual images. The images will be saved inside a new folder under the images directory, called __chicken_frames__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../../video/orangutan.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.12.100\n",
      "  Duration: 00:00:27.48, start: 0.000000, bitrate: 2317 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x720, 2242 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x55c5b9ceeb60] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to '%05d_orangutan.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 720x720, q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc57.107.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n",
      "frame=  141 fps=0.0 q=24.8 size=N/A time=00:00:04.70 bitrate=N/A speed=9.38x    \r",
      "frame=  294 fps=293 q=24.8 size=N/A time=00:00:09.80 bitrate=N/A speed=9.78x    \r",
      "frame=  447 fps=297 q=24.8 size=N/A time=00:00:14.90 bitrate=N/A speed= 9.9x    \r",
      "frame=  597 fps=298 q=24.8 size=N/A time=00:00:19.90 bitrate=N/A speed=9.92x    \r",
      "frame=  751 fps=299 q=24.8 size=N/A time=00:00:25.03 bitrate=N/A speed=9.98x    \r",
      "frame=  823 fps=301 q=24.8 Lsize=N/A time=00:00:27.43 bitrate=N/A speed=  10x    \n",
      "video:17560kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/images/ &&\n",
    "    mkdir ${VIDEO_NAME} && cd ${VIDEO_NAME} &&\n",
    "    ffmpeg -i ../../video/${VIDEO_NAME}.mp4 %05d_${VIDEO_NAME}.jpg -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of frames that the video produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/images/${VIDEO_NAME} && ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our file system should have the following under the folder __pytorch_style_transfer__:\n",
    "```md\n",
    "├── images/\n",
    "│   ├── video_name/ [<--new dir with video frames as images]\n",
    "│   ├── sample_content_images/\n",
    "│   ├── sample_output_images/\n",
    "│   └── style_images/\n",
    "├── video/\n",
    "│   ├── video_name.mp4 [<--new video]\n",
    "│   └── video_name.mp3 [<--new extracted audio file for video]\n",
    "├── style_transfer_interactive.ipynb\n",
    "└── style_transfer_script.py\n",
    "```\n",
    "\n",
    "Now that we have all the frames of the video stored seperately as images, we are ready to scale out and try scoring in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Style Transfer Script on Azure BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use Azure BatchAI to scale out of computation to multiple GPUs in Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create your cluster using the __azure/scripts/create_cluster.py__ script.\n",
    "\n",
    "This script will create the BatchAI workspace for all BatchAI resources to be created in.\n",
    "\n",
    "After running this command, go into the Azure portal and check that your cluster is successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: steady; Allocated: 0; Idle: 0; Unusable: 0; Running: 0; Preparing: 0; Leaving: 0\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python azure/scripts/create_cluster.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files into Azure Blob Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the script and model files to the fileshare using __az_copy__. We'll also upload our content images to test our Batch AI jobs. \n",
    "\n",
    "After running this command, go into the Azure portal or the Azure Storage Explorer and make sure that the files are correctly uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018/09/18 19:09:14] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:00\n",
      "[2018/09/18 19:09:15] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:00\n",
      "[2018/09/18 19:09:17] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 823\n",
      "Transfer successfully:   823\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:01\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source pytorch/style_transfer_script.py \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_SCRIPT_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/style_images/sample_renior.jpg \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_STYLE_IMG_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/${VIDEO_NAME} \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_CONTENT_DIR} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY \\\n",
    "    --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets test that our style transfer script works on the Batch AI cluster. Use the __azure/scripts/create_job.py__ script to kick off a job. \n",
    "\n",
    "Kicking off this job will also automatically create 2 additional folders in your Blob container. The first folder will be named __output_of_content_YYYY_MM_DD_HHMMSS__ and the second will be named __logs_of_content_YYYY_MM_DD_HHMMSS__. The style transfer script will automatically save all output of the style transfer to the first folder. And likewise, all logs collected from the style transfer script will be saved to the second folder.\n",
    "\n",
    "NOTE - this command could take a while to execute. Remember that this will apply style transfer onto each frame of the video - this means that the code will optimize the style transfer loss function for every frame. \n",
    "\n",
    "After running this command, go into the Azure portal under your BatchAI account to make sure the job is sucessfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-18 19:09:48,895 - __main__ - DEBUG - Created job #0, named job0_09_18_2018_190932, with 50 images.\n",
      "2018-09-18 19:10:05,074 - __main__ - DEBUG - Created job #1, named job1_09_18_2018_190948, with 50 images.\n",
      "2018-09-18 19:10:21,702 - __main__ - DEBUG - Created job #2, named job2_09_18_2018_191005, with 50 images.\n",
      "2018-09-18 19:10:38,304 - __main__ - DEBUG - Created job #3, named job3_09_18_2018_191021, with 50 images.\n",
      "2018-09-18 19:10:54,652 - __main__ - DEBUG - Created job #4, named job4_09_18_2018_191038, with 50 images.\n",
      "2018-09-18 19:11:11,072 - __main__ - DEBUG - Created job #5, named job5_09_18_2018_191054, with 50 images.\n",
      "2018-09-18 19:11:27,393 - __main__ - DEBUG - Created job #6, named job6_09_18_2018_191111, with 50 images.\n",
      "2018-09-18 19:11:43,647 - __main__ - DEBUG - Created job #7, named job7_09_18_2018_191127, with 50 images.\n",
      "2018-09-18 19:11:59,937 - __main__ - DEBUG - Created job #8, named job8_09_18_2018_191143, with 50 images.\n",
      "2018-09-18 19:12:15,996 - __main__ - DEBUG - Created job #9, named job9_09_18_2018_191159, with 50 images.\n",
      "2018-09-18 19:12:31,569 - __main__ - DEBUG - Created job #10, named job10_09_18_2018_191215, with 50 images.\n",
      "2018-09-18 19:12:47,447 - __main__ - DEBUG - Created job #11, named job11_09_18_2018_191231, with 50 images.\n",
      "2018-09-18 19:13:04,215 - __main__ - DEBUG - Created job #12, named job12_09_18_2018_191247, with 50 images.\n",
      "2018-09-18 19:13:20,830 - __main__ - DEBUG - Created job #13, named job13_09_18_2018_191304, with 50 images.\n",
      "2018-09-18 19:13:36,777 - __main__ - DEBUG - Created job #14, named job14_09_18_2018_191320, with 50 images.\n",
      "2018-09-18 19:13:53,439 - __main__ - DEBUG - Created job #15, named job15_09_18_2018_191336, with 50 images.\n",
      "2018-09-18 19:14:09,683 - __main__ - DEBUG - Created job #16, named job16_09_18_2018_191353, with 23 images.\n",
      "2018-09-18 19:14:09,683 - __main__ - DEBUG - Time (in seconds) it took to create all BatchAI jobs: 277.66417050361633\n",
      "2018-09-18 19:14:09,683 - __main__ - DEBUG - Time (in seconds) it takes to create a single BatchAI job on average: 17.35401065647602\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python azure/scripts/create_job.py --job-batch-size 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the jobs finish running, you can use the Azure portal or Storage explorer to inspect the output images.\n",
    "\n",
    "Inside your Blob Container, you should notice that a new directory with the datetime-stamp is created. Output images are stored there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running it with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've tested that the BatchAI jobs are successfully created, we now want to build a docker container and check that we can run the BatchAI job from a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build the docker image using the Dockerfile which will upload all Azure utility python files as well as the __create_job.py__ file into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker build -t $DOCKER_IMAGE ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional] \n",
    "\n",
    "Then we test that the BatchAI job can be executed from the docker image we just built. Because the __create_job.py__ file requires many environment variables, we will use the __docker_run.sh__ script to pass in all the required environment variables for the image to successfully run locally. This step is optional as it will take several minutes to run the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    source docker_run.sh -t $DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to publish the image to Dockerhub. _Make sure you replace <your-dockerhub-username>_ with your Dockerhub username. Don't forget that you'll have to make sure you're already logged in before being able to push your image up. (`docker login`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker tag $DOCKER_IMAGE $DOCKER_USER/$DOCKER_IMAGE &&\n",
    "    sudo docker push $DOCKER_USER/$DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up ACI with Logic Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to generate the ARM deployment template for deploying ACI and Logic App to set up the trigger. We will use the __generate_trigger_arm.py__ script to generate an ARM Template (JSON) which we can use to deploy the ACI and Logic App. The script uses __azure/deployments/template.trigger_arm.json__ to generate __azure/deployments/trigger_arm.json__, which we can use to execute the deployment.\n",
    "\n",
    "If you inspect the ARM Template, you'll see that Logic App will be triggered when a new file is added to the blob. The trigger will only occur if the blob filename begins with 'trigger' and ends with '.txt'. It will then use the contents of the blob to look for the corresponding directory in that Blob Container, which it then uses as the content image file directory for the transfer.\n",
    "\n",
    "For example, if we upload a file, titled `trigger_0.txt`, with the content \"content_image_dir\", the Logic App will look for a directory in the Blob Container titled \"content_image_dir\", and start to process the images it finds in the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets generate the trigger template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure/arm &&\n",
    "    python ../scripts/generate_trigger_arm.py trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also just make sure that you've set the correct subscription in the __az cli__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az account set -s $SUBSCRIPTION_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the __az cli__ to deploy the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group deployment create \\\n",
    "    --name aci_logicapp_deployment \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --template-file azure/arm/trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to trigger the process by loading something into blob. Normally, this can be done with any process (such as drag-and-drop using Storage Explorer), but for the purposes of this demo, lets do so simply with __az_copy__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a file, __foo.txt__ with the contents being the name of the directory in the blob that we want to apply style transfer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch trigger_0.txt &&\n",
    "    echo $FS_CONTENT_DIR > trigger_0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to copy that file over to storage to trigger the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source trigger_0.txt \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/trigger_0.txt \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the logs from ACI to see that everything is going smoothly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az container logs --resource-group $RESOURCE_GROUP --name $ACI_CONTAINER_GROUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can inspect the Azure portal to see all the moving parts:\n",
    "- Logic Apps will be triggers and will spin up ACI\n",
    "- ACI will break up the content images in blob and create BatchAI jobs\n",
    "- The BatchAI cluster will scale up and start processing the work\n",
    "- As the style transfer script is executed in batch on BatchAI, we will see the completed images (as well as logs) saved back to blob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results and Re-stitch Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to download and restitch the video so that we can enjoy the same video, but now with each frame with style transfer applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to get the name of the output folder where all out style transfered frames are stored. We do this by using the Batch AI CLI. We store the name of the output folder as `output_folder_name` to be used in later cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use `--query [-1].name` to mean: 'get the name of the last experiment'\n",
    "exp_names = !az batchai experiment list -g ${RESOURCE_GROUP} --workspace ${WORKSPACE} --query [-1].name\n",
    "\n",
    "# strip quotation marks\n",
    "exp_name = str(exp_names[0])[1:-1]\n",
    "\n",
    "# replace experiment prefix with output folder prefix\n",
    "exp_name_array = str(exp_name).split('_')\n",
    "exp_name_array[0] = \"{0}_{1}\".format(os.getenv('FS_OUTPUT_DIR_PREFIX'), os.getenv('FS_CONTENT_DIR'))\n",
    "output_folder_name = '_'.join(exp_name_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `output_folder_name` variable, lets download the frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env output_folder_name=\"$output_folder_name\" bash\n",
    "cd pytorch/images &&\n",
    "    azcopy \\\n",
    "        --source https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME} \\\n",
    "        --destination . \\\n",
    "        --source-key $STORAGE_ACCOUNT_KEY \\\n",
    "        --include $output_folder_name \\\n",
    "        --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets use ffmpeg to stitch independent frames back into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script env output_folder_name=\"$output_folder_name\" bash\n",
    "cd pytorch &&\n",
    "    ffmpeg \\\n",
    "        -framerate 30 \\\n",
    "        -i images/$output_folder_name/%05d_${VIDEO_NAME}.jpg \\\n",
    "        -c:v libx264 \\\n",
    "        -profile:v high -crf 20 -pix_fmt yuv420p \\\n",
    "        -y \\\n",
    "        video/${VIDEO_NAME}_processed_without_audio.mp4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i ${VIDEO_NAME}_processed_without_audio.mp4 -i ${VIDEO_NAME}.mp3 \\\n",
    "        -map 0:0 -map 1:0 \\\n",
    "        -vcodec copy -acodec copy \\\n",
    "        -y \\\n",
    "        ${VIDEO_NAME}_processed_with_audio.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('\\\n",
    "    <video width=\"360\" height=\"360\" controls> \\\n",
    "         <source src=\"pytorch/video/{0}_processed_with_audio.mp4\" type=\"video/mp4\"> \\\n",
    "    </video>'\\\n",
    "    .format(os.getenv('VIDEO_NAME'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = Image(filename=\"pytorch/images/{0}/00001_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "im2 = Image(filename=\"pytorch/images/{0}/00100_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "im3 = Image(filename=\"pytorch/images/{0}/00300_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "im4 = Image(filename=\"pytorch/images/{0}/00500_{1}.jpg\".format(output_folder_name, os.getenv('VIDEO_NAME')))\n",
    "display(im1, im2, im3, im4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its always good to clean up your Azure resources after you've completed your workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group delete --name $RESOURCE_GROUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:batchscoringdl]",
   "language": "python",
   "name": "conda-env-batchscoringdl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
