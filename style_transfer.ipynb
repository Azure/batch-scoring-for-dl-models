{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Azure to do Style Transfer on a Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will take you through how to take a video, and apply style transfer onto every frame of the video, using Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside __/pytorch/images__, you should find a __/style_images__ folder and a __/sample_content_images__ folder.\n",
    "\n",
    "- Inside the __/style_images__ folder is an image of Vangogh painting (titled, __sample_vangogh.jpg__) that we will be using as our sample style image. \n",
    "- Inside the __/sample_content_images__ folder, which we will use solely for the purposes of testing locally, there are 4 sample images that we will use to apply the style onto. (images are titled, __sample_%1.jpg__)\n",
    "\n",
    "The interactive notebook (__style_transfer_interactive.ipynb__) and the script (__style_transfer_script.py__) will using the above directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Tuning the style transfer hyperparameters interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we want to do is to test the style transfer scripts locally and make sure the hyper parameters are set appropriately. This will be done using the __style_transfer_interactive.ipynb__ notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the notebook __/pytorch/style_transfer_interactive.ipynb__ and tune the variables following variables as desired: \n",
    "\n",
    "- STYLE_WEIGHT = 10**8\n",
    "- CONTENT_WEIGHT = 10**0\n",
    "- NUM_STEPS = 300\n",
    "\n",
    "*the defaults shown above _tend_ to work nicely for most images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the style transfer script locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make sure that our style transfer script is running correctly on our local machine. First we need to create the directory to store the output images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you changed the hyperparameters in the above section and would like to apply it, you can use the following variables: `--style-weight`, `--content-weight`, and/or `--num-steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-15 15:20:54,993 - __main__ - DEBUG - Images to process: 2\n",
      "2018-08-15 15:20:54,993 - __main__ - DEBUG - GPU detected: True, image size: 512\n",
      "./images/sample_content_images\n",
      "['sample_0.jpg', 'sample_1.jpg']\n",
      "['sample_3.jpg', 'sample_2.jpg', 'sample_1.jpg', 'sample_0.jpg']\n",
      "['sample_0.jpg', 'sample_1.jpg']\n",
      "2018-08-15 15:20:58,868 - __main__ - DEBUG - Time (in seconds) to load style image: 3.874996\n",
      "2018-08-15 15:21:00,393 - __main__ - DEBUG - Time (in seconds) to load VGG19 model: 1.524280\n",
      "2\n",
      "HELP: ('sample_0.jpg',)\n",
      "2018-08-15 15:21:00,474 - __main__ - DEBUG - Running Style Transfer on sample_0.jpg\n",
      "HELP: ('sample_1.jpg',)\n",
      "2018-08-15 15:22:21,742 - __main__ - DEBUG - Running Style Transfer on sample_1.jpg\n",
      "2018-08-15 15:23:43,708 - __main__ - DEBUG - Time (in seconds) to apply style-transfer to batch of 2 images: 163.315064\n",
      "2018-08-15 15:23:43,708 - __main__ - DEBUG - Average Time (in seconds) to apply style-transfer to each image: 81.657532\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    python style_transfer_script.py \\\n",
    "    --style-image ./images/style_images/sample_vangogh.jpg \\\n",
    "    --content-image-dir ./images/sample_content_images \\\n",
    "    --content-image-list 'sample_0.jpg,sample_1.jpg' \\\n",
    "    --output-image-dir ./images/sample_output_images \\\n",
    "    --style-weight 100000000 \\\n",
    "    --content-weight 1 \\\n",
    "    --num-steps 300 \\\n",
    "    --log-file 'sample_style_transfer_script'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the output directory to make sure that the output images are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_0.jpg\n",
      "sample_1.jpg\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls pytorch/images/sample_output_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what one of those images look like:\n",
    "\n",
    "![sample_1](pytorch/images/sample_output_images/sample_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your video for batch style transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Video: \n",
    "_TODO - update to use MSFT compliant video_\n",
    "\n",
    "The first thing we need to do is to download a video that we would like to apply style transfer onto. To do so, we'll be using __youtube-dl__, a simple open source command line utility to download a video from YouTube. We'll keep the downloaded video in a new folder: __pytorch/video__. \n",
    "\n",
    "First we'll download __youtube-dl__ and use it to download a video. In this notebook, we're going to download a short one and a half minute video of chickens. In the download command, we'll also use the flag `-f 22` to tell __youtube_dl__ that we want to download an mp4 format with dimensions 720x1280. \n",
    "\n",
    "*Feel free to manually place your own video (mp4) file into that directory instead of using __youtube-dl__ to download one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir pytorch/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: youtube-dl in /usr/local/lib/python2.7/dist-packages\n",
      "[youtube] D23sMvVnrow: Downloading webpage\n",
      "[youtube] D23sMvVnrow: Downloading video info webpage\n",
      "[download] Destination: chicken.mp4\n",
      "\r",
      "[download]   0.0% of 23.41MiB at Unknown speed ETA Unknown ETA\r",
      "[download]   0.0% of 23.41MiB at  1.42MiB/s ETA 00:16\r",
      "[download]   0.0% of 23.41MiB at  3.09MiB/s ETA 00:07\r",
      "[download]   0.1% of 23.41MiB at  2.11MiB/s ETA 00:11\r",
      "[download]   0.1% of 23.41MiB at  3.18MiB/s ETA 00:07\r",
      "[download]   0.3% of 23.41MiB at  4.17MiB/s ETA 00:05\r",
      "[download]   0.5% of 23.41MiB at  5.74MiB/s ETA 00:04\r",
      "[download]   1.1% of 23.41MiB at  9.03MiB/s ETA 00:02\r",
      "[download]   2.1% of 23.41MiB at 14.86MiB/s ETA 00:01\r",
      "[download]   4.3% of 23.41MiB at 24.90MiB/s ETA 00:00\r",
      "[download]   8.5% of 23.41MiB at 42.54MiB/s ETA 00:00\r",
      "[download]  17.1% of 23.41MiB at 65.19MiB/s ETA 00:00\r",
      "[download]  34.2% of 23.41MiB at 47.31MiB/s ETA 00:00\r",
      "[download]  51.3% of 23.41MiB at 52.42MiB/s ETA 00:00\r",
      "[download]  68.3% of 23.41MiB at 52.01MiB/s ETA 00:00\r",
      "[download]  85.4% of 23.41MiB at 51.22MiB/s ETA 00:00\r",
      "[download] 100.0% of 23.41MiB at 54.98MiB/s ETA 00:00\r",
      "[download] 100% of 23.41MiB in 00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 8.1.1, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sudo -H pip install --upgrade youtube-dl &&\n",
    "    cd pytorch/video &&\n",
    "    youtube-dl -f 22 -o \"chicken.%(ext)s\" \"https://www.youtube.com/watch?v=D23sMvVnrow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process video with ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to use __ffmpeg__ to extract the audio file, which we will save as __chicken.aac__ under the video directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 2.8.14-0ubuntu0.16.04.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 5.4.0 (Ubuntu 5.4.0-6ubuntu1~16.04.9) 20160609\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.16.04.1 --build-suffix=-ffmpeg --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --cc=cc --cxx=g++ --enable-gpl --enable-shared --disable-stripping --disable-decoder=libopenjpeg --disable-decoder=libschroedinger --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmodplug --enable-libmp3lame --enable-libopenjpeg --enable-libopus --enable-libpulse --enable-librtmp --enable-libschroedinger --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxvid --enable-libzvbi --enable-openal --enable-opengl --enable-x11grab --enable-libdc1394 --enable-libiec61883 --enable-libzmq --enable-frei0r --enable-libx264 --enable-libopencv\n",
      "  libavutil      54. 31.100 / 54. 31.100\n",
      "  libavcodec     56. 60.100 / 56. 60.100\n",
      "  libavformat    56. 40.101 / 56. 40.101\n",
      "  libavdevice    56.  4.100 / 56.  4.100\n",
      "  libavfilter     5. 40.101 /  5. 40.101\n",
      "  libavresample   2.  1.  0 /  2.  1.  0\n",
      "  libswscale      3.  1.101 /  3.  1.101\n",
      "  libswresample   1.  2.101 /  1.  2.101\n",
      "  libpostproc    53.  3.100 / 53.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'chicken.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2017-09-23 09:38:19\n",
      "  Duration: 00:01:39.61, start: 0.000000, bitrate: 1971 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 1842 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "Output #0, adts, to 'chicken.aac':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf56.40.101\n",
      "    Stream #0:0(und): Audio: aac (mp4a / 0x6134706D), 44100 Hz, stereo, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "size=    1557kB time=00:01:39.61 bitrate= 128.0kbits/s    \n",
      "video:0kB audio:1527kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.920026%\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd pytorch/video &&\n",
    "    ffmpeg -i chicken.mp4 -vn -acodec copy chicken.aac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need break up the frames of the video into separate individual images. The images will be saved inside a new folder under the images directory, called __chicken_frames__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../../video/chicken.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2017-09-23 09:38:19\n",
      "  Duration: 00:01:39.61, start: 0.000000, bitrate: 1971 kb/s\n",
      "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709), 1280x720 [SAR 1:1 DAR 16:9], 1842 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 125 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "[swscaler @ 0x18abd60] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to '%05d_chicken.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    encoder         : Lavf56.40.101\n",
      "    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2017-09-23 09:38:19\n",
      "      handler_name    : ISO Media file produced by Google Inc. Created on: 09/23/2017.\n",
      "      encoder         : Lavc56.60.100 mjpeg\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "frame=   82 fps=0.0 q=24.8 size=N/A time=00:00:03.28 bitrate=N/A    \r",
      "frame=  168 fps=167 q=24.8 size=N/A time=00:00:06.72 bitrate=N/A    \r",
      "frame=  255 fps=169 q=24.8 size=N/A time=00:00:10.20 bitrate=N/A    \r",
      "frame=  343 fps=170 q=24.8 size=N/A time=00:00:13.72 bitrate=N/A    \r",
      "frame=  430 fps=171 q=24.8 size=N/A time=00:00:17.20 bitrate=N/A    \r",
      "frame=  514 fps=170 q=24.8 size=N/A time=00:00:20.56 bitrate=N/A    \r",
      "frame=  596 fps=169 q=24.8 size=N/A time=00:00:23.84 bitrate=N/A    \r",
      "frame=  677 fps=168 q=24.8 size=N/A time=00:00:27.08 bitrate=N/A    \r",
      "frame=  761 fps=168 q=24.8 size=N/A time=00:00:30.44 bitrate=N/A    \r",
      "frame=  840 fps=167 q=24.8 size=N/A time=00:00:33.60 bitrate=N/A    \r",
      "frame=  919 fps=166 q=24.8 size=N/A time=00:00:36.76 bitrate=N/A    \r",
      "frame=  996 fps=165 q=24.8 size=N/A time=00:00:39.84 bitrate=N/A    \r",
      "frame= 1072 fps=164 q=24.8 size=N/A time=00:00:42.88 bitrate=N/A    \r",
      "frame= 1149 fps=163 q=24.8 size=N/A time=00:00:45.96 bitrate=N/A    \r",
      "frame= 1225 fps=162 q=24.8 size=N/A time=00:00:49.00 bitrate=N/A    \r",
      "frame= 1300 fps=161 q=24.8 size=N/A time=00:00:52.00 bitrate=N/A    \r",
      "frame= 1374 fps=161 q=24.8 size=N/A time=00:00:54.96 bitrate=N/A    \r",
      "frame= 1449 fps=160 q=24.8 size=N/A time=00:00:57.96 bitrate=N/A    \r",
      "frame= 1523 fps=159 q=24.8 size=N/A time=00:01:00.92 bitrate=N/A    \r",
      "frame= 1596 fps=159 q=24.8 size=N/A time=00:01:03.84 bitrate=N/A    \r",
      "frame= 1669 fps=158 q=24.8 size=N/A time=00:01:06.76 bitrate=N/A    \r",
      "frame= 1745 fps=158 q=24.8 size=N/A time=00:01:09.80 bitrate=N/A    \r",
      "frame= 1819 fps=157 q=24.8 size=N/A time=00:01:12.76 bitrate=N/A    \r",
      "frame= 1893 fps=157 q=24.8 size=N/A time=00:01:15.72 bitrate=N/A    \r",
      "frame= 1969 fps=157 q=24.8 size=N/A time=00:01:18.76 bitrate=N/A    \r",
      "frame= 2046 fps=156 q=24.8 size=N/A time=00:01:21.84 bitrate=N/A    \r",
      "frame= 2123 fps=156 q=24.8 size=N/A time=00:01:24.92 bitrate=N/A    \r",
      "frame= 2198 fps=156 q=24.8 size=N/A time=00:01:27.92 bitrate=N/A    \r",
      "frame= 2273 fps=156 q=24.8 size=N/A time=00:01:30.92 bitrate=N/A    \r",
      "frame= 2350 fps=156 q=24.8 size=N/A time=00:01:34.00 bitrate=N/A    \r",
      "frame= 2431 fps=156 q=24.8 size=N/A time=00:01:37.24 bitrate=N/A    \r",
      "frame= 2490 fps=156 q=24.8 Lsize=N/A time=00:01:39.60 bitrate=N/A    \n",
      "video:101655kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/images/ &&\n",
    "    mkdir chicken_frames && cd chicken_frames &&\n",
    "    ffmpeg -i ../../video/chicken.mp4 %05d_chicken.jpg -hide_banner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of frames that the video produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2490\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd pytorch/images/chicken_frames && ls -1 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, our file system should have the following under the folder __pytorch_style_transfer__:\n",
    "```md\n",
    "├── images/\n",
    "│   ├── chicken_frames/ [<--new dir with video frames as images]\n",
    "│   ├── sample_content_images/\n",
    "│   ├── sample_output_images/\n",
    "│   └── style_images/\n",
    "├── video/\n",
    "│   ├── chicken.mp4 [<--new video]\n",
    "│   └── chicken.avi [<--new extracted audio file for video]\n",
    "├── style_transfer_interactive.ipynb\n",
    "└── style_transfer_script.py\n",
    "```\n",
    "\n",
    "Now that we have all the frames of the video stored seperately as images, we are ready to scale out and try scoring in the cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Style Transfer Script on Azure BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use Azure BatchAI to scale out of computation to multiple GPUs in Azure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create your cluster using the __azure/scripts/create_cluster.py__ script.\n",
    "\n",
    "This script will create the BatchAI workspace for all BatchAI resources to be created in.\n",
    "\n",
    "After running this command, go into the Azure portal and check that your cluster is successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: resizing; Allocated: 0; Idle: 0; Unusable: 0; Running: 0; Preparing: 0; Leaving: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: No recommended backend was available. Install the keyrings.alt package if you want to use the non-recommended backends. See README.rst for details.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python azure/scripts/create_cluster.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload files into Azure Blob Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the script and model files to the fileshare using __az_copy__. We'll also upload our content images to test our Batch AI jobs. \n",
    "\n",
    "After running this command, go into the Azure portal or the Azure Storage Explorer and make sure that the files are correctly uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018/08/15 18:46:42] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:00\n",
      "[2018/08/15 18:46:43] Transfer summary:\n",
      "-----------------\n",
      "Total files transferred: 1\n",
      "Transfer successfully:   1\n",
      "Transfer skipped:        0\n",
      "Transfer failed:         0\n",
      "Elapsed time:            00.00:00:00\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source pytorch/style_transfer_script.py \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_SCRIPT_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/style_images/sample_vangogh.jpg \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_INPUT_DIR}/${FS_STYLE_IMG_NAME} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY\n",
    "    \n",
    "azcopy \\\n",
    "    --source pytorch/images/chicken_frames \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/${FS_CONTENT_DIR} \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY \\\n",
    "    --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Test job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets test that our style transfer script works on the Batch AI cluster. Use the __azure/scripts/create_job.py__ script to kick off a job. \n",
    "\n",
    "NOTE - this command could take a while to execute. Remember that this will apply style transfer onto each frame of the video - this means that the code will optimize the style transfer loss function for every frame. \n",
    "\n",
    "After running this command, go into the Azure portal under your BatchAI account to make sure the job is sucessfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-15 15:38:56,282 - __main__ - DEBUG - Created job #0, named job0_08_15_2018_153838, with 100 images.\n",
      "2018-08-15 15:39:13,807 - __main__ - DEBUG - Created job #1, named job1_08_15_2018_153856, with 100 images.\n",
      "2018-08-15 15:39:31,311 - __main__ - DEBUG - Created job #2, named job2_08_15_2018_153913, with 100 images.\n",
      "2018-08-15 15:39:48,765 - __main__ - DEBUG - Created job #3, named job3_08_15_2018_153931, with 100 images.\n",
      "2018-08-15 15:40:05,569 - __main__ - DEBUG - Created job #4, named job4_08_15_2018_153948, with 100 images.\n",
      "2018-08-15 15:40:21,966 - __main__ - DEBUG - Created job #5, named job5_08_15_2018_154005, with 100 images.\n",
      "2018-08-15 15:40:37,841 - __main__ - DEBUG - Created job #6, named job6_08_15_2018_154021, with 100 images.\n",
      "2018-08-15 15:40:54,577 - __main__ - DEBUG - Created job #7, named job7_08_15_2018_154037, with 100 images.\n",
      "2018-08-15 15:41:12,036 - __main__ - DEBUG - Created job #8, named job8_08_15_2018_154054, with 100 images.\n",
      "2018-08-15 15:41:28,673 - __main__ - DEBUG - Created job #9, named job9_08_15_2018_154112, with 100 images.\n",
      "2018-08-15 15:41:45,412 - __main__ - DEBUG - Created job #10, named job10_08_15_2018_154128, with 100 images.\n",
      "2018-08-15 15:42:01,265 - __main__ - DEBUG - Created job #11, named job11_08_15_2018_154145, with 100 images.\n",
      "2018-08-15 15:42:17,529 - __main__ - DEBUG - Created job #12, named job12_08_15_2018_154201, with 100 images.\n",
      "2018-08-15 15:42:34,821 - __main__ - DEBUG - Created job #13, named job13_08_15_2018_154217, with 100 images.\n",
      "2018-08-15 15:42:51,768 - __main__ - DEBUG - Created job #14, named job14_08_15_2018_154234, with 100 images.\n",
      "2018-08-15 15:43:07,753 - __main__ - DEBUG - Created job #15, named job15_08_15_2018_154251, with 100 images.\n",
      "2018-08-15 15:43:24,863 - __main__ - DEBUG - Created job #16, named job16_08_15_2018_154307, with 100 images.\n",
      "2018-08-15 15:43:40,884 - __main__ - DEBUG - Created job #17, named job17_08_15_2018_154324, with 100 images.\n",
      "2018-08-15 15:43:57,081 - __main__ - DEBUG - Created job #18, named job18_08_15_2018_154340, with 100 images.\n",
      "2018-08-15 15:44:13,607 - __main__ - DEBUG - Created job #19, named job19_08_15_2018_154357, with 100 images.\n",
      "2018-08-15 15:44:29,699 - __main__ - DEBUG - Created job #20, named job20_08_15_2018_154413, with 100 images.\n",
      "2018-08-15 15:44:45,829 - __main__ - DEBUG - Created job #21, named job21_08_15_2018_154429, with 100 images.\n",
      "2018-08-15 15:45:03,166 - __main__ - DEBUG - Created job #22, named job22_08_15_2018_154445, with 100 images.\n",
      "2018-08-15 15:45:21,168 - __main__ - DEBUG - Created job #23, named job23_08_15_2018_154503, with 100 images.\n",
      "2018-08-15 15:45:38,462 - __main__ - DEBUG - Created job #24, named job24_08_15_2018_154521, with 90 images.\n",
      "2018-08-15 15:45:38,462 - __main__ - DEBUG - Time (in seconds) it took to create all BatchAI jobs: 419.9919321537018\n",
      "2018-08-15 15:45:38,462 - __main__ - DEBUG - Time (in seconds) it takes to create a single BatchAI job on average: 17.499663839737575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: No recommended backend was available. Install the keyrings.alt package if you want to use the non-recommended backends. See README.rst for details.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python azure/scripts/create_job.py --job-batch-size 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the jobs finish running, you can use the Azure portal or Storage explorer to inspect the output images.\n",
    "\n",
    "Inside your Blob Container, you should notice that a new directory with the datetime-stamp is created. Output images are stored there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running it with Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've tested that the BatchAI jobs are successfully created, we now want to build a docker container and check that we can run the BatchAI job from a docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build the docker image using the Dockerfile which will upload all Azure utility python files as well as the __create_job.py__ file into the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker build -t $DOCKER_IMAGE ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to test that the BatchAI job can be executed from the docker image we just built. Because the __create_job.py__ file requires many environment variables, we will use the __docker_run.sh__ script to pass in all the required environment variables for the image to successfully run locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    source docker_run.sh -t $DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to publish the image to Dockerhub. _Make sure you replace <your-dockerhub-username>_ with your Dockerhub username. Don't forget that you'll have to make sure you're already logged in before being able to push your image up. (`docker login`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/jiata/bai_job]\n",
      "1c622ccb3a18: Preparing\n",
      "8b43734718b2: Preparing\n",
      "2caef9d2922c: Preparing\n",
      "511e6a804a09: Preparing\n",
      "6aca85ba2c1f: Preparing\n",
      "0c5d1b2a1642: Preparing\n",
      "66a1aa763275: Preparing\n",
      "6db858a45525: Preparing\n",
      "1385e3b82428: Preparing\n",
      "f3693db46abb: Preparing\n",
      "bb6d734b467e: Preparing\n",
      "5f349fdc9028: Preparing\n",
      "2c833f307fd8: Preparing\n",
      "f3693db46abb: Waiting\n",
      "66a1aa763275: Waiting\n",
      "6db858a45525: Waiting\n",
      "bb6d734b467e: Waiting\n",
      "5f349fdc9028: Waiting\n",
      "2c833f307fd8: Waiting\n",
      "1385e3b82428: Waiting\n",
      "6aca85ba2c1f: Layer already exists\n",
      "1c622ccb3a18: Layer already exists\n",
      "2caef9d2922c: Layer already exists\n",
      "8b43734718b2: Layer already exists\n",
      "511e6a804a09: Layer already exists\n",
      "f3693db46abb: Layer already exists\n",
      "66a1aa763275: Layer already exists\n",
      "1385e3b82428: Layer already exists\n",
      "6db858a45525: Layer already exists\n",
      "bb6d734b467e: Layer already exists\n",
      "5f349fdc9028: Layer already exists\n",
      "2c833f307fd8: Layer already exists\n",
      "0c5d1b2a1642: Layer already exists\n",
      "latest: digest: sha256:aa62f694656008ad70fcaad82b4c4838a8489674f58943af46f727a0f1f87df8 size: 3048\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd azure &&\n",
    "    sudo docker tag bai_job $DOCKER_USER/$DOCKER_IMAGE &&\n",
    "    sudo docker push $DOCKER_USER/$DOCKER_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up ACI with Logic Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to generate the ARM deployment template for deploying ACI and Logic App to set up the trigger. We will use the __generate_trigger_arm.py__ script to generate an ARM Template (JSON) which we can use to deploy the ACI and Logic App. The script uses __azure/deployments/template.trigger_arm.json__ to generate __azure/deployments/trigger_arm.json__, which we can use to execute the deployment.\n",
    "\n",
    "If you inspect the ARM Template, you'll see that Logic App will be triggered when a new file is added to the blob. The trigger will only occur if the blob filename begins with 'trigger' and ends with '.txt'. It will then use the contents of the blob to look for the corresponding directory in that Blob Container, which it then uses as the content image file directory for the transfer.\n",
    "\n",
    "For example, if we upload a file, titled `trigger_0.txt`, with the content \"content_image_dir\", the Logic App will look for a directory in the Blob Container titled \"content_image_dir\", and start to process the images it finds in the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets generate the trigger template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd azure/arm &&\n",
    "    python ../scripts/generate_trigger_arm.py trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the __az cli__ to deploy the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Resources/deployments/aci_logicapp_deployment\",\n",
      "  \"name\": \"aci_logicapp_deployment\",\n",
      "  \"properties\": {\n",
      "    \"correlationId\": \"b8314479-c507-473d-bca3-f4b4f3828be5\",\n",
      "    \"debugSetting\": null,\n",
      "    \"dependencies\": [\n",
      "      {\n",
      "        \"dependsOn\": [\n",
      "          {\n",
      "            \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Web/connections/aci\",\n",
      "            \"resourceGroup\": \"jsbatchai\",\n",
      "            \"resourceName\": \"aci\",\n",
      "            \"resourceType\": \"Microsoft.Web/connections\"\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Web/connections/azureblob\",\n",
      "            \"resourceGroup\": \"jsbatchai\",\n",
      "            \"resourceName\": \"azureblob\",\n",
      "            \"resourceType\": \"Microsoft.Web/connections\"\n",
      "          }\n",
      "        ],\n",
      "        \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Logic/workflows/js_logic_app\",\n",
      "        \"resourceGroup\": \"jsbatchai\",\n",
      "        \"resourceName\": \"js_logic_app\",\n",
      "        \"resourceType\": \"Microsoft.Logic/workflows\"\n",
      "      }\n",
      "    ],\n",
      "    \"duration\": \"PT14.7575578S\",\n",
      "    \"mode\": \"Incremental\",\n",
      "    \"outputResources\": [\n",
      "      {\n",
      "        \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Logic/workflows/js_logic_app\",\n",
      "        \"resourceGroup\": \"jsbatchai\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Web/connections/aci\",\n",
      "        \"resourceGroup\": \"jsbatchai\"\n",
      "      },\n",
      "      {\n",
      "        \"id\": \"/subscriptions/0ca618d2-22a8-413a-96d0-0f1b531129c3/resourceGroups/jsbatchai/providers/Microsoft.Web/connections/azureblob\",\n",
      "        \"resourceGroup\": \"jsbatchai\"\n",
      "      }\n",
      "    ],\n",
      "    \"outputs\": null,\n",
      "    \"parameters\": {\n",
      "      \"connections_aci_name\": {\n",
      "        \"type\": \"String\",\n",
      "        \"value\": \"aci\"\n",
      "      },\n",
      "      \"connections_azureblob_name\": {\n",
      "        \"type\": \"String\",\n",
      "        \"value\": \"azureblob\"\n",
      "      },\n",
      "      \"workflows_js_logic_app_name\": {\n",
      "        \"type\": \"String\",\n",
      "        \"value\": \"js_logic_app\"\n",
      "      },\n",
      "      \"workflows_jsbatchai_path\": {\n",
      "        \"type\": \"String\",\n",
      "        \"value\": \"/subscriptions/@{encodeURIComponent('0ca618d2-22a8-413a-96d0-0f1b531129c3')}/resourceGroups/@{encodeURIComponent('jsbatchai')}/providers/Microsoft.ContainerInstance/containerGroups/@{encodeURIComponent('js_aci_group')}\"\n",
      "      }\n",
      "    },\n",
      "    \"parametersLink\": null,\n",
      "    \"providers\": [\n",
      "      {\n",
      "        \"id\": null,\n",
      "        \"namespace\": \"Microsoft.Logic\",\n",
      "        \"registrationState\": null,\n",
      "        \"resourceTypes\": [\n",
      "          {\n",
      "            \"aliases\": null,\n",
      "            \"apiVersions\": null,\n",
      "            \"locations\": [\n",
      "              \"eastus\"\n",
      "            ],\n",
      "            \"properties\": null,\n",
      "            \"resourceType\": \"workflows\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"id\": null,\n",
      "        \"namespace\": \"Microsoft.Web\",\n",
      "        \"registrationState\": null,\n",
      "        \"resourceTypes\": [\n",
      "          {\n",
      "            \"aliases\": null,\n",
      "            \"apiVersions\": null,\n",
      "            \"locations\": [\n",
      "              \"eastus\"\n",
      "            ],\n",
      "            \"properties\": null,\n",
      "            \"resourceType\": \"connections\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ],\n",
      "    \"provisioningState\": \"Succeeded\",\n",
      "    \"template\": null,\n",
      "    \"templateHash\": \"13981102772283752125\",\n",
      "    \"templateLink\": null,\n",
      "    \"timestamp\": \"2018-08-15T18:20:47.469860+00:00\"\n",
      "  },\n",
      "  \"resourceGroup\": \"jsbatchai\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "az group deployment create \\\n",
    "    --name aci_logicapp_deployment \\\n",
    "    --resource-group $RESOURCE_GROUP \\\n",
    "    --template-file azure/arm/trigger_arm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to trigger the process by loading something into blob. Normally, this can be done with any process, but for the purposes of this demo, lets do so simply with __az_copy__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a file, __foo.txt__ with the contents being the name of the directory in the blob that we want to apply style transfer too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "touch trigger_0.txt &&\n",
    "    echo $FS_CONTENT_DIR > trigger_0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to copy that file over to storage to trigger the process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "azcopy \\\n",
    "    --source trigger_0.txt \\\n",
    "    --destination https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME}/trigger_0.txt \\\n",
    "    --dest-key $STORAGE_ACCOUNT_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can inspect the Azure portal to see all the moving parts:\n",
    "- Logic Apps will be triggers and will spin up ACI\n",
    "- ACI will break up the content images in blob and create BatchAI jobs\n",
    "- The BatchAI cluster will scale up and start processing the work\n",
    "- As the style transfer script is executed in batch on BatchAI, we will see the completed images (as well as logs) saved back to blob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results and Re-stitch Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to download and restitch the video so that we can enjoy the same video, but now with each frame with style transfer applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to download the frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch/images &&\n",
    "    azcopy \\\n",
    "        --source https://${STORAGE_ACCOUNT_NAME}.blob.core.windows.net/${AZURE_CONTAINER_NAME} \\\n",
    "        --destination . \\\n",
    "        --source-key $STORAGE_ACCOUNT_KEY \\\n",
    "        --include \"output_content_08_08_2018_162725\" \\\n",
    "        --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then lets use ffmpeg to stitch independent frames back into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd pytorch &&\n",
    "    ffmpeg \\\n",
    "        -framerate 30 \\\n",
    "        -i images/\"output_content_08_08_2018_162725\"/%05d_chicken.jpg \\\n",
    "        -c:v libx264 \\\n",
    "        -profile:v high -crf 20 -pix_fmt yuv420p \\\n",
    "        video/chicken_processed.mp4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its always good to clean up your Azure resources after you've completed your workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "az group delete --name $RESOURCE_GROUP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
