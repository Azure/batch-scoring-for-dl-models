# export all vars as environment variables
set -a

# =========================
# Credentials 
# =========================

# the following fields can be found from creating a service principal
# please reference the link below for instructions on how to create a service principal
# https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli

AAD_CLIENT_ID='<aad_client_guid>'
AAD_SECRET='<aad_secret>'
AAD_TENANT='<aad_tenant>'

# the following fields can be found from your storage account

STORAGE_ACCOUNT_NAME='<storage_account_name>'
STORAGE_ACCOUNT_KEY='<storage_account_key>'

# Enter the desired username/password for ssh-ing into your batch ai cluster

ADMIN_USER_NAME='<some_username>'
ADMIN_USER_PASSWORD='<some_password>'


# =========================
# Account
# =========================

# the subscription id of your azure account
SUBSCRIPTION_ID='<subscription_id>'

# ex. 'batchscoringrg' 
RESOURCE_GROUP='<resource_group_name>'

# ex. 'eastus' - please reference ____ for available locations
REGION='<azure_region>'


# =========================
# Azure Blob (BFS)
# =========================

# ex. 'share' - name of the azure blob container
AZURE_CONTAINER_NAME='<name of your file_share>'

# ex. 'input' - directory for scripts & style image
FS_INPUT_DIR='input'

# name of script in blob to use
FS_SCRIPT_NAME='script.py'

# name of style image in blob to use
FS_STYLE_IMG_NAME='style.jpg'

# ex. 'content' - directory for content images
FS_CONTENT_DIR='content'

# ex. 'output_imgs_of' - directory for output images
FS_OUTPUT_DIR_PREFIX='output_of'

# ex. 'logs_of' - directory to dump logs
FS_LOGGER_DIR_PREFIX='logs_of'


# =========================
# BatchAI 
# =========================

# ex. 'my_workspace'
WORKSPACE='<workspace name>'

# ex. 'exp'
EXPERIMENT_PREFIX='<experiment prefix>'

# ex. 'job' - each job has the id: <prefix_mm_dd_yyyy_time>
JOB_NAME_PREFIX='<prefix of job name>'

# ex. '1' - number of nodes to use for the job
JOB_NODE_COUNT='<num nodes for job>'

# job batch size (number of images to process per job)
JOB_BATCH_SIZE='<num images to process per job>'

# ex. 'bob_nc6_0'
CLUSTER_NAME='<name of your cluster>'

# ex. 'bfs'
CLUSTER_CONTAINER_MNT_PATH='<blob_container_mnt_path>'

# ex. 'STANDARD_NC6' -  please reference ____ for available vm sizes TODO
CLUSTER_VM_SIZE='<vm_size>'

# 'dedicated' or 'low-priority'
CLUSTER_VM_PRIORITY='<vm_priority>'

# Following fields are used if 'auto_scale' is set to True
CLUSTER_MINIMUM_NODE_COUNT='<min nodes in cluster>'
CLUSTER_MAXIMUM_NODE_COUNT='<max nodes in cluster>'
CLUSTER_INITIAL_NODE_COUNT='<initial nodes in cluster>'

# =========================
# LOGIC APP / ACI  
# =========================

# Name of logic app
LOGIC_APP='<my_logic_app>'

# ACI Container group name
ACI_CONTAINER_GROUP='<my_aci_containers>'

# ACI display name etc 'hello@outlook.com'
ACI_DISPLAY_NAME='<username>@<domain>'

# Docker image name etc. 'batchai_job_runner'
DOCKER_IMAGE='<docker_image_name>'

# Docker repo user - name of dockerhub username
DOCKER_USER='<docker_username>'


